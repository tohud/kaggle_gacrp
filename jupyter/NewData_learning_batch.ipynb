{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#前処理後のindex作るための処理\n",
    "import os\n",
    "import elasticsearch as es\n",
    "import math\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ES_HOST = \"localhost\"\n",
    "escon = es.Elasticsearch(ES_HOST, port=9200,timeout=300)\n",
    "GACRP_HOME=os.environ['GACRP_HOME']\n",
    "\n",
    "# ESのデータ量依存設定値のグローバル変数化\n",
    "# scrollのタイムアウト時間\n",
    "es_s_time='60m'\n",
    "\n",
    "maxPartition=90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練データの期間\n",
    " #for化済み\n",
    "    \n",
    "#評価データの期間\n",
    "evalIndataStartYmd=20180101\n",
    "evalIndataEndYmd=20180631\n",
    "evalForecastStartYmd=20180801\n",
    "evalForecastEndYmd=20180931\n",
    "\n",
    "#教師データから変換した項目数（one-hot後）\n",
    "# Todo 配列の形式から自動設定にする。\n",
    "num_elements=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2date(num,flg):\n",
    "    mm=num%12\n",
    "    yy=2016+num/12\n",
    "    if mm == 0:\n",
    "        mm=12\n",
    "        yy-=1\n",
    "    if flg==\"start\":\n",
    "        dd=1\n",
    "    else:\n",
    "        dd=31\n",
    "    return(yy*10000+mm*100+dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 元データ取得\n",
    "\n",
    "def getInputData(startymd,endymd):\n",
    "    es_size=10000\n",
    "    body = {\n",
    "      \"_source\": [\n",
    "        \"fullVisitorId\",\"date\",\n",
    "        \"channelGrouping\",\"visitNumber\",\"device_isMobile\",\"geoNetwork_country\",\"totals_hits\",\"totals_bounces\",\n",
    "        \"totals_newVisits\",\"trafficSource_source\",\"trafficSource_medium\",\"trafficSource_isTrueDirect\",\"totals_transactionRevenue\"\n",
    "      ],\n",
    "      \"query\": {\n",
    "        \"bool\": {\n",
    "          \"must\": [\n",
    "            {\n",
    "              \"range\": {\n",
    "                \"date\": {\n",
    "                  \"gt\": startymd,\n",
    "                  \"lt\": endymd\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          ],\n",
    "          \"must_not\": [],\n",
    "          \"should\": []\n",
    "        }\n",
    "      },\n",
    "      \"from\": 0,\n",
    "      \"size\": 0,\n",
    "      \"sort\": [],\n",
    "      \"aggs\": {}\n",
    "    }\n",
    "  \n",
    "    res=escon.search(index='gacrp_v2_index',doc_type='gacrp_v2_type',body=body,scroll=es_s_time,size=es_size)\n",
    "    es_s_id=res['_scroll_id']\n",
    "    es_s_size=len(res[\"hits\"][\"hits\"])\n",
    "    \n",
    "    return(res,es_s_id,es_s_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fullVisitorIdごとに、指定した期間のrevenueを取得\n",
    "def getRevenue(startYmd,endYmd,partitionNumber,maxPartition):\n",
    "    es_size=10000\n",
    "    body = {\n",
    "        \"size\":0,\n",
    "        \"aggs\":{\n",
    "            \"agg_fullVisitorId\":{\n",
    "                \"terms\":{\n",
    "                    \"field\":\"fullVisitorId.keyword\",\n",
    "                    \"include\":{\n",
    "                        \"partition\":partitionNumber,\n",
    "                        \"num_partitions\":maxPartition\n",
    "                    },\n",
    "                    \"size\":10000\n",
    "                },\n",
    "                \"aggs\":{\n",
    "                    \"agg_revenue\":{\n",
    "                        \"sum\":{\"field\":\"totals_transactionRevenue\"}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"query\":{\n",
    "            \"bool\":{\n",
    "                \"must\":[\n",
    "                    {\"range\": {\"date\": {\n",
    "                                \"gt\": startYmd,\"lt\": endYmd\n",
    "                    }}}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    #print(body)\n",
    "    res=escon.search(index='gacrp_v2_index',doc_type='gacrp_v2_type',body=body)\n",
    "    #revenue=math.log(int(res['aggregations']['agg_revenue']['value'])+1)\n",
    "    #print(revenue)\n",
    "    return(res['aggregations']['agg_fullVisitorId']['buckets'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oneHotベクトル化\n",
    "def es2oneHot(res,data):\n",
    "    for i in range(len(res[\"hits\"][\"hits\"])):\n",
    "        row=res[\"hits\"][\"hits\"][i][\"_source\"]\n",
    "        rec=[]\n",
    "\n",
    "        col_date=row['date']\n",
    "        col_fullVisitorId=row['fullVisitorId']\n",
    "        \n",
    "        if row['channelGrouping']=='Display':\n",
    "            col_channelGrouping=1\n",
    "        elif row['channelGrouping']=='Social':\n",
    "            col_channelGrouping=2\n",
    "        else:\n",
    "            col_channelGrouping=0\n",
    "        oneHot_col_channelGrouping=np.eye(2+1)[col_channelGrouping]\n",
    "        \n",
    "        #visitNumberは最大を5で打ち切って0～1にnormalize。\n",
    "        col_visitNumber=min(int(row['visitNumber']),5)/5.0 \n",
    "\n",
    "        if row['device_isMobile']==\"True\":\n",
    "            col_isMobile=1\n",
    "        else:\n",
    "            col_isMobile=0\n",
    "\n",
    "        if row['geoNetwork_country']==\"United States\":\n",
    "            col_country =1\n",
    "        elif row['geoNetwork_country']==\"Canada\":\n",
    "            col_country =2\n",
    "        elif row['geoNetwork_country']==\"Japan\":\n",
    "            col_country=3\n",
    "        else:\n",
    "            col_country=0\n",
    "        oneHot_col_country=np.eye(3+1)[col_country]\n",
    "    \n",
    "        col_hits=math.log10(int(row['totals_hits'])*1.0)\n",
    "    \n",
    "        if row['totals_bounces']==\"1\":\n",
    "            col_bounces=1\n",
    "        else:\n",
    "            col_bounces=0\n",
    "\n",
    "        if row['totals_newVisits']== \"1\":\n",
    "            col_newVisits=1\n",
    "        else:\n",
    "            col_newVisits=0\n",
    "    \n",
    "        if row['trafficSource_source']==\"mail.googleplex.com\" or row['trafficSource_source']==\"dfa\":\n",
    "            col_source =1\n",
    "        elif row['trafficSource_source']==\"(direct)\":\n",
    "            col_source=2\n",
    "        else:\n",
    "            col_source=0\n",
    "        oneHot_col_source=np.eye(2+1)[col_source]\n",
    "        \n",
    "        if row['trafficSource_medium']==\"cpm\":\n",
    "            col_medium=1\n",
    "        else:\n",
    "            col_medium=0\n",
    "        oneHot_col_medium=np.eye(1+1)[col_medium]\n",
    "    \n",
    "        if row['trafficSource_isTrueDirect']==\"1\":\n",
    "            col_isTrueDirect=1\n",
    "        else:\n",
    "            col_isTrueDirect=0\n",
    "    \n",
    "        #revenue = math.log(int(row['transactionRevenue'])+1)\n",
    "    \n",
    "        l=[oneHot_col_channelGrouping,[col_visitNumber],[col_isMobile],oneHot_col_country,[col_hits],[col_bounces],[col_newVisits],oneHot_col_source,oneHot_col_medium,[col_isTrueDirect]]\n",
    "        data.append([col_fullVisitorId,list(chain.from_iterable(l))])\n",
    "        #data.append([col_fullVisitorId,l])\n",
    "        #ans.append(revenue)\n",
    "    \n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rowdataを対象期間のfullVisitorIdごとに集約する\n",
    "def transformInputdata(rowdata):\n",
    "    rowdata=sorted(rowdata,key=lambda x:x[0])\n",
    "    print(\"ソート完了\")\n",
    "    key_fullVisitorId=rowdata[0][0]\n",
    "    sumdata=[]\n",
    "\n",
    "    tmp_indata=[]\n",
    "    tmp_indata.append(rowdata[0][1])\n",
    "    tmp_cnt=1\n",
    "    for i in range(1,len(rowdata)):\n",
    "        if i %100000==0:\n",
    "            print(\"集約処理実行中：\"+str(i) )\n",
    "        if key_fullVisitorId==rowdata[i][0]:\n",
    "            tmp_indata.append(rowdata[i][1])\n",
    "            tmp_cnt+=1\n",
    "        else:\n",
    "            #列方向に平均をとってappend\n",
    "            #print(tmp_indata)\n",
    "            tmp_np = np.empty((0,18),float)\n",
    "            for j in range(tmp_cnt):\n",
    "                tmp_np = np.append(tmp_np,np.array([tmp_indata[j]]),axis=0)\n",
    "            sumdata.append([key_fullVisitorId,np.average(tmp_np,axis=0).tolist()])\n",
    "        #ans.append(getRevenueByFullVisitorId(key_fullVisitorId,forecastStartYmd,forecastEndYmd))\n",
    "            key_fullVisitorId=rowdata[i][0]\n",
    "            tmp_indata=[]\n",
    "            tmp_indata.append(rowdata[i][1])\n",
    "            tmp_cnt=1\n",
    "\n",
    "    tmp_np = np.empty((0,18),float)\n",
    "    for j in range(tmp_cnt):\n",
    "        tmp_np = np.append(tmp_np,np.array([tmp_indata[j]]),axis=0)\n",
    "    sumdata.append([key_fullVisitorId,np.average(tmp_np,axis=0)])\n",
    "    print(len(sumdata))\n",
    "    \n",
    "    return(sumdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#集約後のfullVisitorIdにRevenueをjoinする\n",
    "#print(tmpans[0])\n",
    "def joinRevenue(sumdata,tmpans):\n",
    "    ans=[]\n",
    "    #npans=np.array(tmpans)\n",
    "    #print(npans[0])\n",
    "    print(sumdata[0][0])\n",
    "\n",
    "    tmpans=sorted(tmpans,key=lambda x:x[0])\n",
    "    print(\"tmpansソート完了\"+str(len(tmpans)) )\n",
    "    print(tmpans[0])\n",
    "\n",
    "    key_ans=tmpans[0][0]\n",
    "    ix_ans=0\n",
    "    key_data=sumdata[0][0]\n",
    "    ix_data=0\n",
    "    inf = '9999999999999999999'\n",
    "\n",
    "    while key_ans != inf or key_data != inf:\n",
    "        if key_ans == key_data:\n",
    "            ans.append(tmpans[ix_ans][1])\n",
    "            ix_data+=1\n",
    "            ix_ans+=1\n",
    "        elif key_ans > key_data:\n",
    "            ans.append(0)\n",
    "            ix_data+=1\n",
    "        else:\n",
    "            ix_ans+=1\n",
    "        if ix_ans >= len(tmpans):\n",
    "            key_ans=inf\n",
    "        else:\n",
    "            key_ans=tmpans[ix_ans][0]\n",
    "\n",
    "        if ix_data >= len(sumdata):\n",
    "            key_data=inf\n",
    "        else:\n",
    "            key_data=sumdata[ix_data][0]\n",
    "\n",
    "    print(len(ans))\n",
    "    print(sum(ans))\n",
    "    \n",
    "    return(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モジュールロード完了\n",
      "訓練データ読込開始:20160801\n",
      "訓練データ読込:10000\n",
      "訓練データ読込:20000\n",
      "訓練データ読込:30000\n",
      "訓練データ読込:40000\n",
      "訓練データ読込:50000\n",
      "訓練データ読込:60000\n",
      "訓練データ読込:70000\n",
      "訓練データ読込:80000\n",
      "訓練データ読込:90000\n",
      "訓練データ読込:100000\n",
      "訓練データ読込:110000\n",
      "訓練データ読込:120000\n",
      "訓練データ読込:130000\n",
      "訓練データ読込:140000\n",
      "訓練データ読込:150000\n",
      "訓練データ読込:160000\n",
      "訓練データ読込:170000\n",
      "訓練データ読込:180000\n",
      "訓練データ読込:190000\n",
      "訓練データ読込:200000\n",
      "訓練データ読込:210000\n",
      "訓練データ読込:220000\n",
      "訓練データ読込:230000\n",
      "訓練データ読込:240000\n",
      "訓練データ読込:250000\n",
      "訓練データ読込:260000\n",
      "訓練データ読込:270000\n",
      "訓練データ読込:280000\n",
      "訓練データ読込:290000\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "NotFoundError(404, u'search_phase_execution_exception', u'No search context found for id [14]')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-e6c3fd2d02cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mes_s_size\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mrowdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mes2oneHot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrowdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mescon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscroll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscroll_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mes_s_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mes_s_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mes_s_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_scroll_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mes_s_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/elasticsearch/client/utils.pyc\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/elasticsearch/client/__init__.pyc\u001b[0m in \u001b[0;36mscroll\u001b[0;34m(self, scroll_id, body, params)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         return self.transport.perform_request('GET', '/_search/scroll',\n\u001b[0;32m-> 1016\u001b[0;31m             params=params, body=body)\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/elasticsearch/transport.pyc\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mdelay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mattempt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                 \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTransportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.pyc\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_request_fail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         self.log_request_success(method, full_url, url, body, response.status,\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/elasticsearch/connection/base.pyc\u001b[0m in \u001b[0;36m_raise_error\u001b[0;34m(self, status_code, raw_data)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Undecodable raw error response from server: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTP_EXCEPTIONS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransportError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: NotFoundError(404, u'search_phase_execution_exception', u'No search context found for id [14]')"
     ]
    }
   ],
   "source": [
    "#訓練データ読み込み\n",
    "#rowdata=[]\n",
    "print(\"モジュールロード完了\")\n",
    "ans = []\n",
    "sumdata=[]\n",
    "\n",
    "#for i in range(8,29+1):\n",
    "for i in range(8,19+1):\n",
    "    rowdata=[]\n",
    "    indataStartYmd=num2date(i,\"start\")\n",
    "    indataEndYmd  =num2date(i+5,\"end\")\n",
    "    print(\"訓練データ読込開始:\"+str(indataStartYmd) )\n",
    "    res,es_s_id,es_s_size=getInputData(indataStartYmd,indataEndYmd)\n",
    "    \n",
    "    while(es_s_size>0):\n",
    "        rowdata=es2oneHot(res,rowdata)\n",
    "        res=escon.scroll(scroll_id=es_s_id,scroll=es_s_time)\n",
    "        es_s_id=res['_scroll_id']\n",
    "        es_s_size=len(res[\"hits\"][\"hits\"])\n",
    "        print(\"訓練データ読込:\"+str(len(rowdata)) )\n",
    "\n",
    "    tmpdata=transformInputdata(rowdata)\n",
    "    for j in range(len(tmpdata)):\n",
    "        sumdata.append(tmpdata[j])\n",
    "    \n",
    "    #partitionでぐるぐる回してtransactionRevenueをとってくる\n",
    "    #sumdataに合わせてansを当てて設定する。\n",
    "\n",
    "    tmpans=[]\n",
    "    forecastStartYmd=num2date(i+7,\"start\")\n",
    "    forecastEndYmd=num2date(i+8,\"end\")\n",
    "    for partitionNumber in range(maxPartition):\n",
    "        res=getRevenue(forecastStartYmd,forecastEndYmd,partitionNumber,maxPartition)\n",
    "        for i in range(len(res)):\n",
    "            tmpans.append([res[i]['key'], math.log(int(res[i]['agg_revenue']['value'])+1)])\n",
    "\n",
    "    tmpans2=joinRevenue(tmpdata,tmpans)\n",
    "\n",
    "    for j in range(len(tmpans2)):\n",
    "        ans.append(tmpans2[j])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#評価データ読み込み\n",
    "evalrowdata=[]\n",
    "evalans = []\n",
    "\n",
    "# 評価データは期間を固定\n",
    "\n",
    "res,es_s_id,es_s_size=getInputData(evalIndataStartYmd,evalIndataEndYmd)\n",
    "while(es_s_size>0):\n",
    "    rowdata=es2oneHot(res,evalrowdata)\n",
    "    res=escon.scroll(scroll_id=es_s_id,scroll=es_s_time)\n",
    "    es_s_id=res['_scroll_id']\n",
    "    es_s_size=len(res[\"hits\"][\"hits\"])\n",
    "\n",
    "    print(\"評価データ読込:\"+str(len(evalrowdata)) )\n",
    "\n",
    "evalsumdata=transformInputdata(evalrowdata)\n",
    "\n",
    "#partitionでぐるぐる回してtransactionRevenueをとってくる\n",
    "#sumdataに合わせてansを当てて設定する。\n",
    "\n",
    "evaltmpans=[]\n",
    "for partitionNumber in range(maxPartition):\n",
    "    #print(partitionNumber)\n",
    "    res=getRevenue(evalForecastStartYmd,evalForecastEndYmd,partitionNumber,maxPartition)\n",
    "    for i in range(len(res)):\n",
    "        evaltmpans.append([res[i]['key'], math.log(int(res[i]['agg_revenue']['value'])+1)])\n",
    "\n",
    "evalans=joinRevenue(evalsumdata,evaltmpans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflowセットアップ\n",
    "datalength=len(sumdata)\n",
    "\n",
    "#print(data[0],ans[0])\n",
    "#inputData=tf.transpose(data)\n",
    "debugFlg=False\n",
    "batch_size=datalength/2\n",
    "\n",
    "P=int(36)\n",
    "Q=int(36)\n",
    "\n",
    "num_rows=len(sumdata)\n",
    "#sumdataから１列目を削除してinputDataに渡す\n",
    "#data=[]\n",
    "#for i in range(len(sumdata)):\n",
    "    #data.append(sumdata[i][1][0])\n",
    "\n",
    "#print(sumdata[14])\n",
    "\n",
    "#高速化のため見直し\n",
    "#data=np.empty((0,num_elements))\n",
    "#for i in range(len(sumdata)):\n",
    "#    data=np.append(data,[np.array(sumdata[i][1])],axis=0 )\n",
    "#    if i % 10000==0:\n",
    "#        print(i)\n",
    "\n",
    "##訓練データをtensorflowが食えるように変換\n",
    "data=np.empty((0,num_elements))\n",
    "tmp_array=data.tolist()\n",
    "for i in range(len(sumdata)):\n",
    "    tmp_array.append(np.array(sumdata[i][1]))\n",
    "data=np.asarray(tmp_array)        \n",
    "print(data.shape)\n",
    "\n",
    "inputData=data\n",
    "inputAns=np.reshape(ans,(num_rows,1))\n",
    "\n",
    "\n",
    "#print(data[0:20])\n",
    "\n",
    "##評価データを同様に設定\n",
    "evalnum_rows=len(evalsumdata)\n",
    "evaldata=np.empty((0,num_elements))\n",
    "evaltmp_array=evaldata.tolist()\n",
    "for i in range(len(evalsumdata)):\n",
    "    evaltmp_array.append(np.array(evalsumdata[i][1]))\n",
    "evaldata=np.asarray(evaltmp_array)\n",
    "print(evaldata.shape)\n",
    "\n",
    "evalInputData=evaldata\n",
    "evalAns=np.reshape(evalans,(evalnum_rows,1))\n",
    "\n",
    "\n",
    "#inputData=np.reshape(np.delete(sumdata,0,1),(num_rows,num_elements))\n",
    "#inputData=np.reshape(sumdata[:][1],(num_rows,num_elements))\n",
    "##inputData=np.reshape(data,(num_rows,num_elements))\n",
    "#inputData=data,(num_rows,num_elements)\n",
    "x =tf.placeholder(\"float\",[None,num_elements])\n",
    "y_=tf.placeholder(\"float\",[None,1])\n",
    "\n",
    "a=tf.Variable( tf.random_uniform([num_elements,1],-1.0,1.0),name=\"weights\")    \n",
    "w1=tf.Variable( tf.random_uniform([num_elements,P],-1.0,1.0 )  )\n",
    "w2=tf.Variable( tf.random_uniform([P,Q],-1.0,1.0 )  )\n",
    "w3=tf.Variable( tf.random_uniform([Q,1],-1.0,1.0 )  )\n",
    "\n",
    "#a=tf.Variable( tf.random_uniform([[18]],-1.0,1.0),name=\"weights\")    \n",
    "#b=tf.Variable(tf.zeros([1,1]),name=\"intercept\")\n",
    "b=tf.Variable(tf.random_normal([P]),name=\"intercept\")\n",
    "print(\"x:\",x.shape,\"a:\",a.shape)\n",
    "#y=tf.matmul(tf.transpose(a),x)+b\n",
    "#y=tf.matmul(x,a)\n",
    "\n",
    "x2=tf.sigmoid(tf.matmul(x,w1))+b\n",
    "#y=tf.matmul(x2,w2)\n",
    "x3=tf.sigmoid(tf.matmul(x2,w2))\n",
    "y =tf.matmul(x3,w3)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "loss = tf.reduce_sum(tf.square(y_-y))/batch_size\n",
    "train_step=tf.train.GradientDescentOptimizer(0.0001).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#データ表示用セットアップ\n",
    "# 基準となる全部ゼロ時の値\n",
    "print(\"sum of math.log(transactionRevenue):\"+str(sum(ans)/batch_size ) )\n",
    "\n",
    "graphLoss=[]\n",
    "graphEval=[]\n",
    "graphStep=[]\n",
    "graphNum=30\n",
    "repeatAll=3000\n",
    "debugFlg=False\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print('初期状態')\n",
    "    inpShape=inputData[0:batch_size]\n",
    "    ansShape=inputAns[0:batch_size]\n",
    "    #print('誤差' + str(sess.run(loss, feed_dict={x: inputData[0:batch_size], y_: inputAns[0:batch_size]})))\n",
    "    ##print('誤差' + str(sess.run(loss, feed_dict={x: inpShape, y_: ansShape})))\n",
    "    #print(\"weigths: %f, intercept: %f\" % (sess.run(a), sess.run(b) ))\n",
    "    #print(\"input:\",inputAns[batch_size*step+1:batch_size*step+1+batch_size])\n",
    "    ##print(\"weigths:\",sess.run(a),\"intercept:\",sess.run(b) )\n",
    "    \n",
    "    for step in range(repeatAll):\n",
    "        if (batch_size*step) %datalength < (batch_size*step+batch_size) %datalength :\n",
    "            batchInputData= inputData[(batch_size*step)%datalength:(batch_size*step+batch_size)%datalength]\n",
    "            batchInputAns = inputAns[(batch_size*step)%datalength:(batch_size*step+batch_size)%datalength]\n",
    "        else:\n",
    "            batchInputData= inputData[(batch_size*step)%datalength:min( (batch_size*step+batch_size)%datalength,datalength-1 )]\n",
    "            batchInputAns = inputAns[(batch_size*step)%datalength:min( (batch_size*step+batch_size)%datalength,datalength-1) ]\n",
    "        sess.run(train_step, feed_dict={x: batchInputData, y_: batchInputAns })\n",
    "        if (step+1) % (repeatAll/graphNum) == 0:\n",
    "            print('\\nStep: %s' % (step+1))\n",
    "            print('誤差' + str(sess.run(loss, feed_dict={x: batchInputData, y_: batchInputAns })))\n",
    "            print('評価' + str(sess.run(loss, feed_dict={x: evalInputData, y_: evalAns })))\n",
    "            if debugFlg==True:\n",
    "                print(\"weights:\",sess.run(w1), \" intercept:\", sess.run(b) )\n",
    "            graphLoss.append( sess.run(loss, feed_dict={x: batchInputData, y_: batchInputAns }) )\n",
    "            graphEval.append( sess.run(loss, feed_dict={x: evalInputData, y_: evalAns }))\n",
    "            graphStep.append(step)\n",
    "    #最終状態を表示\n",
    "    print(\"weights1:\",sess.run(w1),\"weights2:\",sess.run(w2), \" intercept:\", sess.run(b))\n",
    "    \n",
    "    \n",
    "# めも\n",
    "#Step: 10000\n",
    "#誤差0.574773\n",
    "#評価1.05919"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "plt.plot(graphStep,graphLoss,graphStep,graphEval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## todo 全部予想結果ゼロの場合のスコアがどのくらいかを見てみる。\n",
    "\n",
    "## todo 学習した結果の重みを使って予想を計算する。\n",
    "## sess.runした結果を整形すればいいはず。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
