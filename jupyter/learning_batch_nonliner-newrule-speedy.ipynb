{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#前処理後のindex作るための処理\n",
    "import os\n",
    "import elasticsearch as es\n",
    "import math\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ES_HOST = \"localhost\"\n",
    "escon = es.Elasticsearch(ES_HOST, port=9200)\n",
    "GACRP_HOME=os.environ['GACRP_HOME']\n",
    "\n",
    "# ESのデータ量依存設定値のグローバル変数化\n",
    "# scrollのタイムアウト時間\n",
    "es_s_time='2m'\n",
    "\n",
    "maxPartition=90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練データの期間\n",
    "indataStartYmd=20160801\n",
    "indataEndYmd=20161031\n",
    "forecastStartYmd=20161101\n",
    "forecastEndYmd=20161231\n",
    "\n",
    "#評価データの期間\n",
    "evalIndataStartYmd=20170201\n",
    "evalIndataEndYmd=20170431\n",
    "evalForecastStartYmd=20170501\n",
    "evalForecastEndYmd=20170631\n",
    "\n",
    "#教師データから変換した項目数（one-hot後）\n",
    "# Todo 配列の形式から自動設定にする。\n",
    "num_elements=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 元データ取得\n",
    "\n",
    "def getInputData(startymd,endymd):\n",
    "    es_size=10000\n",
    "    body = {\n",
    "      \"_source\": [\n",
    "        \"fullVisitorId\",\"date\",\n",
    "        \"channelGrouping\",\"visitNumber\",\"isMobile\",\"country\",\"hits\",\"bounces\",\n",
    "        \"newVisits\",\"source\",\"medium\",\"isTrueDirect\",\"transactionRevenue\"\n",
    "      ],\n",
    "      \"query\": {\n",
    "        \"bool\": {\n",
    "          \"must\": [\n",
    "            {\n",
    "              \"range\": {\n",
    "                \"date\": {\n",
    "                  \"gt\": startymd,\n",
    "                  \"lt\": endymd\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          ],\n",
    "          \"must_not\": [],\n",
    "          \"should\": []\n",
    "        }\n",
    "      },\n",
    "      \"from\": 0,\n",
    "      \"size\": 0,\n",
    "      \"sort\": [],\n",
    "      \"aggs\": {}\n",
    "    }\n",
    "  \n",
    "    res=escon.search(index='gacrp_index',body=body,scroll=es_s_time,size=es_size)\n",
    "    es_s_id=res['_scroll_id']\n",
    "    es_s_size=len(res[\"hits\"][\"hits\"])\n",
    "    \n",
    "    return(res,es_s_id,es_s_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fullVisitorIdごとに、指定した期間のrevenueを取得\n",
    "def getRevenue(startYmd,endYmd,partitionNumber,maxPartition):\n",
    "    es_size=10000\n",
    "    body = {\n",
    "        \"size\":0,\n",
    "        \"aggs\":{\n",
    "            \"agg_fullVisitorId\":{\n",
    "                \"terms\":{\n",
    "                    \"field\":\"fullVisitorId.keyword\",\n",
    "                    \"include\":{\n",
    "                        \"partition\":partitionNumber,\n",
    "                        \"num_partitions\":maxPartition\n",
    "                    },\n",
    "                    \"size\":10000\n",
    "                },\n",
    "                \"aggs\":{\n",
    "                    \"agg_revenue\":{\n",
    "                        \"sum\":{\"field\":\"transactionRevenue\"}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"query\":{\n",
    "            \"bool\":{\n",
    "                \"must\":[\n",
    "                    {\"range\": {\"date\": {\n",
    "                                \"gt\": startYmd,\"lt\": endYmd\n",
    "                    }}}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    #print(body)\n",
    "    res=escon.search(index='gacrp_index',body=body)\n",
    "    #revenue=math.log(int(res['aggregations']['agg_revenue']['value'])+1)\n",
    "    #print(revenue)\n",
    "    return(res['aggregations']['agg_fullVisitorId']['buckets'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oneHotベクトル化\n",
    "def es2oneHot(res,data):\n",
    "    for i in range(len(res[\"hits\"][\"hits\"])):\n",
    "        row=res[\"hits\"][\"hits\"][i][\"_source\"]\n",
    "        rec=[]\n",
    "\n",
    "        col_date=row['date']\n",
    "        col_fullVisitorId=row['fullVisitorId']\n",
    "        \n",
    "        if row['channelGrouping']=='Display':\n",
    "            col_channelGrouping=1\n",
    "        elif row['channelGrouping']=='Social':\n",
    "            col_channelGrouping=2\n",
    "        else:\n",
    "            col_channelGrouping=0\n",
    "        oneHot_col_channelGrouping=np.eye(2+1)[col_channelGrouping]\n",
    "        \n",
    "        #visitNumberは最大を5で打ち切って0～1にnormalize。\n",
    "        col_visitNumber=min(int(row['visitNumber']),5)/5.0 \n",
    "\n",
    "        if row['isMobile']==\"TRUE\":\n",
    "            col_isMobile=1\n",
    "        else:\n",
    "            col_isMobile=0\n",
    "\n",
    "        if row['country']==\"United States\":\n",
    "            col_country =1\n",
    "        elif row['country']==\"Canada\":\n",
    "            col_country =2\n",
    "        elif row['country']==\"Japan\":\n",
    "            col_country=3\n",
    "        else:\n",
    "            col_country=0\n",
    "        oneHot_col_country=np.eye(3+1)[col_country]\n",
    "    \n",
    "        col_hits=math.log10(int(row['hits'])*1.0)\n",
    "    \n",
    "        if row['bounces']==\"1\":\n",
    "            col_bounces=1\n",
    "        else:\n",
    "            col_bounces=0\n",
    "\n",
    "        if row['newVisits']== \"1\":\n",
    "            col_newVisits=1\n",
    "        else:\n",
    "            col_newVisits=0\n",
    "    \n",
    "        if row['source']==\"mail.googleplex.com\" or row['source']==\"dfa\":\n",
    "            col_source =1\n",
    "        elif row['source']==\"(direct)\":\n",
    "            col_source=2\n",
    "        else:\n",
    "            col_source=0\n",
    "        oneHot_col_source=np.eye(2+1)[col_source]\n",
    "        \n",
    "        if row['medium']==\"cpm\":\n",
    "            col_medium=1\n",
    "        else:\n",
    "            col_medium=0\n",
    "        oneHot_col_medium=np.eye(1+1)[col_medium]\n",
    "    \n",
    "        if row['isTrueDirect']==\"1\":\n",
    "            col_isTrueDirect=1\n",
    "        else:\n",
    "            col_isTrueDirect=0\n",
    "    \n",
    "        #revenue = math.log(int(row['transactionRevenue'])+1)\n",
    "    \n",
    "        l=[oneHot_col_channelGrouping,[col_visitNumber],[col_isMobile],oneHot_col_country,[col_hits],[col_bounces],[col_newVisits],oneHot_col_source,oneHot_col_medium,[col_isTrueDirect]]\n",
    "        data.append([col_fullVisitorId,list(chain.from_iterable(l))])\n",
    "        #data.append([col_fullVisitorId,l])\n",
    "        #ans.append(revenue)\n",
    "    \n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "237728\n"
     ]
    }
   ],
   "source": [
    "rowdata=[]\n",
    "ans = []\n",
    "\n",
    "res,es_s_id,es_s_size=getInputData(indataStartYmd,indataEndYmd)\n",
    "while(es_s_size>0):\n",
    "    rowdata=es2oneHot(res,rowdata)\n",
    "    res=escon.scroll(scroll_id=es_s_id,scroll=es_s_time)\n",
    "    es_s_id=res['_scroll_id']\n",
    "    es_s_size=len(res[\"hits\"][\"hits\"])\n",
    "\n",
    "    print(len(rowdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rowdataを対象期間のfullVisitorIdごとに集約して予測期間のtransactionRevenueを当てる\n",
    "def transformInputdata(rowdata):\n",
    "    rowdata=sorted(rowdata,key=lambda x:x[0])\n",
    "    print(\"ソート完了\")\n",
    "    key_fullVisitorId=rowdata[0][0]\n",
    "    sumdata=[]\n",
    "\n",
    "    tmp_indata=[]\n",
    "    tmp_indata.append(rowdata[0][1])\n",
    "    tmp_cnt=1\n",
    "    for i in range(1,len(rowdata)):\n",
    "        #if i %10000==0:\n",
    "        #    print(\"集約処理実行中：\"+str(i) )\n",
    "        if key_fullVisitorId==rowdata[i][0]:\n",
    "            tmp_indata.append(rowdata[i][1])\n",
    "            tmp_cnt+=1\n",
    "        else:\n",
    "            #列方向に平均をとってappend\n",
    "            #print(tmp_indata)\n",
    "            tmp_np = np.empty((0,18),float)\n",
    "            for j in range(tmp_cnt):\n",
    "                tmp_np = np.append(tmp_np,np.array([tmp_indata[j]]),axis=0)\n",
    "            sumdata.append([key_fullVisitorId,np.average(tmp_np,axis=0).tolist()])\n",
    "        #ans.append(getRevenueByFullVisitorId(key_fullVisitorId,forecastStartYmd,forecastEndYmd))\n",
    "            key_fullVisitorId=rowdata[i][0]\n",
    "            tmp_indata=[]\n",
    "            tmp_indata.append(rowdata[i][1])\n",
    "            tmp_cnt=1\n",
    "\n",
    "    tmp_np = np.empty((0,18),float)\n",
    "    for j in range(tmp_cnt):\n",
    "        tmp_np = np.append(tmp_np,np.array([tmp_indata[j]]),axis=0)\n",
    "    sumdata.append([key_fullVisitorId,np.average(tmp_np,axis=0)])\n",
    "    print(len(sumdata))\n",
    "    \n",
    "    return(sumdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ソート完了\n",
      "195131\n"
     ]
    }
   ],
   "source": [
    "sumdata=transformInputdata(rowdata)\n",
    "\n",
    "#partitionでぐるぐる回してtransactionRevenueをとってくる\n",
    "#sumdataに合わせてansを当てて設定する。\n",
    "\n",
    "tmpans=[]\n",
    "for partitionNumber in range(maxPartition):\n",
    "    #print(partitionNumber)\n",
    "    res=getRevenue(forecastStartYmd,forecastEndYmd,partitionNumber,maxPartition)\n",
    "    for i in range(len(res)):\n",
    "        #if i==1:\n",
    "        #    print(res[i])\n",
    "        tmpans.append([res[i]['key'], math.log(int(res[i]['agg_revenue']['value'])+1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#集約後のfullVisitorIdにjoinする\n",
    "#print(tmpans[0])\n",
    "def joinRevenue(sumdata,tmpans):\n",
    "    ans=[]\n",
    "    #npans=np.array(tmpans)\n",
    "    #print(npans[0])\n",
    "    print(sumdata[0][0])\n",
    "\n",
    "    tmpans=sorted(tmpans,key=lambda x:x[0])\n",
    "    print(\"tmpansソート完了\"+str(len(tmpans)) )\n",
    "    print(tmpans[0])\n",
    "\n",
    "    key_ans=tmpans[0][0]\n",
    "    ix_ans=0\n",
    "    key_data=sumdata[0][0]\n",
    "    ix_data=0\n",
    "    inf = '9999999999999999999'\n",
    "\n",
    "    while key_ans != inf or key_data != inf:\n",
    "        if key_ans == key_data:\n",
    "            ans.append(tmpans[ix_ans][1])\n",
    "            ix_data+=1\n",
    "            ix_ans+=1\n",
    "        elif key_ans > key_data:\n",
    "            ans.append(0)\n",
    "            ix_data+=1\n",
    "        else:\n",
    "            ix_ans+=1\n",
    "        if ix_ans >= len(tmpans):\n",
    "            key_ans=inf\n",
    "        else:\n",
    "            key_ans=tmpans[ix_ans][0]\n",
    "\n",
    "        if ix_data >= len(sumdata):\n",
    "            key_data=inf\n",
    "        else:\n",
    "            key_data=sumdata[ix_data][0]\n",
    "\n",
    "#for ix_data in range(len(sumdata)):\n",
    "#    if ix_data % 10000 ==0:\n",
    "#        print(\"join中：\"+str(ix_data))\n",
    "    #r = np.where(npans[:,0]==sumdata[i][0])\n",
    "    \n",
    "    #print(r[0])\n",
    "    #print(\"len:\",len(r[0]))\n",
    "#    if len(r[0])==0:\n",
    "#        ans.append(0)\n",
    "#    else:\n",
    "#        ans.append(r[1]['value'])\n",
    "\n",
    "    #print(getRevenueByFullVisitorId(rowdata[i][0],\"20160101\",\"20180101\"))\n",
    "\n",
    "    print(len(ans))\n",
    "    print(sum(ans))\n",
    "    \n",
    "    return(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000010278554503158\n",
      "tmpansソート完了155959\n",
      "[u'0000020424342248747', 0.0]\n",
      "195131\n",
      "5665.12325108\n"
     ]
    }
   ],
   "source": [
    "ans=joinRevenue(sumdata,tmpans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n"
     ]
    },
    {
     "ename": "ConnectionTimeout",
     "evalue": "ConnectionTimeout caused by - ReadTimeoutError(HTTPConnectionPool(host=u'localhost', port=9200): Read timed out. (read timeout=10))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mConnectionTimeout\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-9bbe33d4ac8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mes_s_size\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mrowdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mes2oneHot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevalrowdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mescon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscroll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscroll_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mes_s_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mes_s_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mes_s_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_scroll_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mes_s_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/elasticsearch/client/utils.pyc\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/elasticsearch/client/__init__.pyc\u001b[0m in \u001b[0;36mscroll\u001b[0;34m(self, scroll_id, body, params)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         return self.transport.perform_request('GET', '/_search/scroll',\n\u001b[0;32m-> 1016\u001b[0;31m             params=params, body=body)\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/elasticsearch/transport.pyc\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mdelay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mattempt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                 \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTransportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/elasticsearch/connection/http_urllib3.pyc\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'N/A'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadTimeoutError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mConnectionTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TIMEOUT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'N/A'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionTimeout\u001b[0m: ConnectionTimeout caused by - ReadTimeoutError(HTTPConnectionPool(host=u'localhost', port=9200): Read timed out. (read timeout=10))"
     ]
    }
   ],
   "source": [
    "#評価データ読み込み\n",
    "evalrowdata=[]\n",
    "evalans = []\n",
    "\n",
    "res,es_s_id,es_s_size=getInputData(evalIndataStartYmd,evalIndataEndYmd)\n",
    "while(es_s_size>0):\n",
    "    rowdata=es2oneHot(res,evalrowdata)\n",
    "    res=escon.scroll(scroll_id=es_s_id,scroll=es_s_time)\n",
    "    es_s_id=res['_scroll_id']\n",
    "    es_s_size=len(res[\"hits\"][\"hits\"])\n",
    "\n",
    "    print(len(evalrowdata))\n",
    "\n",
    "evalsumdata=transformInputdata(evalrowdata)\n",
    "\n",
    "#partitionでぐるぐる回してtransactionRevenueをとってくる\n",
    "#sumdataに合わせてansを当てて設定する。\n",
    "\n",
    "evaltmpans=[]\n",
    "for partitionNumber in range(maxPartition):\n",
    "    #print(partitionNumber)\n",
    "    res=getRevenue(evalForecastStartYmd,evalForecastEndYmd,partitionNumber,maxPartition)\n",
    "    for i in range(len(res)):\n",
    "        evaltmpans.append([res[i]['key'], math.log(int(res[i]['agg_revenue']['value'])+1)])\n",
    "\n",
    "evalans=joinRevenue(evalsumdata,evaltmpans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflowセットアップ\n",
    "datalength=len(sumdata)\n",
    "\n",
    "#print(data[0],ans[0])\n",
    "#inputData=tf.transpose(data)\n",
    "debugFlg=False\n",
    "batch_size=datalength/2\n",
    "\n",
    "P=int(36)\n",
    "Q=int(36)\n",
    "\n",
    "num_rows=len(sumdata)\n",
    "#sumdataから１列目を削除してinputDataに渡す\n",
    "#data=[]\n",
    "#for i in range(len(sumdata)):\n",
    "    #data.append(sumdata[i][1][0])\n",
    "\n",
    "#print(sumdata[14])\n",
    "\n",
    "#高速化のため見直し\n",
    "#data=np.empty((0,num_elements))\n",
    "#for i in range(len(sumdata)):\n",
    "#    data=np.append(data,[np.array(sumdata[i][1])],axis=0 )\n",
    "#    if i % 10000==0:\n",
    "#        print(i)\n",
    "\n",
    "##訓練データをtensorflowが食えるように変換\n",
    "data=np.empty((0,num_elements))\n",
    "tmp_array=data.tolist()\n",
    "for i in range(len(sumdata)):\n",
    "    tmp_array.append(np.array(sumdata[i][1]))\n",
    "data=np.asarray(tmp_array)        \n",
    "print(data.shape)\n",
    "\n",
    "inputData=data\n",
    "inputAns=np.reshape(ans,(num_rows,1))\n",
    "\n",
    "\n",
    "#print(data[0:20])\n",
    "\n",
    "##評価データを同様に設定\n",
    "evalnum_rows=len(evalsumdata)\n",
    "evaldata=np.empty((0,num_elements))\n",
    "evaltmp_array=evaldata.tolist()\n",
    "for i in range(len(evalsumdata)):\n",
    "    evaltmp_array.append(np.array(evalsumdata[i][1]))\n",
    "evaldata=np.asarray(evaltmp_array)\n",
    "print(evaldata.shape)\n",
    "\n",
    "evalInputData=evaldata\n",
    "evalAns=np.reshape(evalans,(evalnum_rows,1))\n",
    "\n",
    "\n",
    "#inputData=np.reshape(np.delete(sumdata,0,1),(num_rows,num_elements))\n",
    "#inputData=np.reshape(sumdata[:][1],(num_rows,num_elements))\n",
    "##inputData=np.reshape(data,(num_rows,num_elements))\n",
    "#inputData=data,(num_rows,num_elements)\n",
    "x =tf.placeholder(\"float\",[None,num_elements])\n",
    "y_=tf.placeholder(\"float\",[None,1])\n",
    "\n",
    "a=tf.Variable( tf.random_uniform([num_elements,1],-1.0,1.0),name=\"weights\")    \n",
    "w1=tf.Variable( tf.random_uniform([num_elements,P],-1.0,1.0 )  )\n",
    "w2=tf.Variable( tf.random_uniform([P,Q],-1.0,1.0 )  )\n",
    "w3=tf.Variable( tf.random_uniform([Q,1],-1.0,1.0 )  )\n",
    "\n",
    "#a=tf.Variable( tf.random_uniform([[18]],-1.0,1.0),name=\"weights\")    \n",
    "#b=tf.Variable(tf.zeros([1,1]),name=\"intercept\")\n",
    "b=tf.Variable(tf.random_normal([P]),name=\"intercept\")\n",
    "print(\"x:\",x.shape,\"a:\",a.shape)\n",
    "#y=tf.matmul(tf.transpose(a),x)+b\n",
    "#y=tf.matmul(x,a)\n",
    "\n",
    "x2=tf.sigmoid(tf.matmul(x,w1))+b\n",
    "#y=tf.matmul(x2,w2)\n",
    "x3=tf.sigmoid(tf.matmul(x2,w2))\n",
    "y =tf.matmul(x3,w3)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "loss = tf.reduce_sum(tf.square(y_-y))/batch_size\n",
    "train_step=tf.train.GradientDescentOptimizer(0.0001).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#データ表示用セットアップ\n",
    "graphLoss=[]\n",
    "graphEval=[]\n",
    "graphStep=[]\n",
    "graphNum=30\n",
    "repeatAll=3000\n",
    "debugFlg=False\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print('初期状態')\n",
    "    inpShape=inputData[0:batch_size]\n",
    "    ansShape=inputAns[0:batch_size]\n",
    "    #print('誤差' + str(sess.run(loss, feed_dict={x: inputData[0:batch_size], y_: inputAns[0:batch_size]})))\n",
    "    ##print('誤差' + str(sess.run(loss, feed_dict={x: inpShape, y_: ansShape})))\n",
    "    #print(\"weigths: %f, intercept: %f\" % (sess.run(a), sess.run(b) ))\n",
    "    #print(\"input:\",inputAns[batch_size*step+1:batch_size*step+1+batch_size])\n",
    "    ##print(\"weigths:\",sess.run(a),\"intercept:\",sess.run(b) )\n",
    "    \n",
    "    for step in range(repeatAll):\n",
    "        if (batch_size*step) %datalength < (batch_size*step+batch_size) %datalength :\n",
    "            batchInputData= inputData[(batch_size*step)%datalength:(batch_size*step+batch_size)%datalength]\n",
    "            batchInputAns = inputAns[(batch_size*step)%datalength:(batch_size*step+batch_size)%datalength]\n",
    "        else:\n",
    "            batchInputData= inputData[(batch_size*step)%datalength:min( (batch_size*step+batch_size)%datalength,datalength-1 )]\n",
    "            batchInputAns = inputAns[(batch_size*step)%datalength:min( (batch_size*step+batch_size)%datalength,datalength-1) ]\n",
    "        sess.run(train_step, feed_dict={x: batchInputData, y_: batchInputAns })\n",
    "        if (step+1) % (repeatAll/graphNum) == 0:\n",
    "            print('\\nStep: %s' % (step+1))\n",
    "            print('誤差' + str(sess.run(loss, feed_dict={x: batchInputData, y_: batchInputAns })))\n",
    "            print('評価' + str(sess.run(loss, feed_dict={x: evalInputData, y_: evalAns })))\n",
    "            if debugFlg==True:\n",
    "                print(\"weights:\",sess.run(w1), \" intercept:\", sess.run(b) )\n",
    "            graphLoss.append( sess.run(loss, feed_dict={x: batchInputData, y_: batchInputAns }) )\n",
    "            graphEval.append( sess.run(loss, feed_dict={x: evalInputData, y_: evalAns }))\n",
    "            graphStep.append(step)\n",
    "    #最終状態を表示\n",
    "    print(\"weights1:\",sess.run(w1),\"weights2:\",sess.run(w2), \" intercept:\", sess.run(b))\n",
    "    \n",
    "    \n",
    "# めも\n",
    "#Step: 10000\n",
    "#誤差0.574773\n",
    "#評価1.05919"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "plt.plot(graphStep,graphLoss,graphStep,graphEval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
