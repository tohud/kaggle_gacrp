{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#前処理後のindex作るための処理\n",
    "import os\n",
    "import elasticsearch as es\n",
    "import math\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ES_HOST = \"localhost\"\n",
    "escon = es.Elasticsearch(ES_HOST, port=9200)\n",
    "GACRP_HOME=os.environ['GACRP_HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "ans = []\n",
    "\n",
    "# 元データ取得\n",
    "es_size=10000\n",
    "es_s_time='2m'\n",
    "body = {\n",
    "    \"_source\":[\"channelGrouping\",\"visitNumber\",\"isMobile\",\"country\",\"hits\",\"bounces\",\"newVisits\",\"source\",\"medium\",\"isTrueDirect\",\"transactionRevenue\"],\n",
    "    \"query\": {\n",
    "      \"match_all\": {}\n",
    "    }\n",
    "  }\n",
    "  \n",
    "res=escon.search(index='gacrp_index',body=body,scroll=es_s_time,size=es_size)\n",
    "es_s_id=res['_scroll_id']\n",
    "es_s_size=len(res[\"hits\"][\"hits\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oneHotベクトル化\n",
    "def setByScroll(res,data,ans):\n",
    "    for i in range(len(res[\"hits\"][\"hits\"])):\n",
    "        row=res[\"hits\"][\"hits\"][i][\"_source\"]\n",
    "        rec=[]\n",
    "\n",
    "        if row['channelGrouping']=='Display':\n",
    "            col_channelGrouping=1\n",
    "        elif row['channelGrouping']=='Social':\n",
    "            col_channelGrouping=2\n",
    "        else:\n",
    "            col_channelGrouping=0\n",
    "        oneHot_col_channelGrouping=np.eye(2+1)[col_channelGrouping]\n",
    "        \n",
    "        col_visitNumber=min(int(row['visitNumber']),5)/5.0 \n",
    "\n",
    "        if row['isMobile']==\"TRUE\":\n",
    "            col_isMobile=1\n",
    "        else:\n",
    "            col_isMobile=0\n",
    "\n",
    "        if row['country']==\"United States\":\n",
    "            col_country =1\n",
    "        elif row['country']==\"Canada\":\n",
    "            col_country =2\n",
    "        elif row['country']==\"Japan\":\n",
    "            col_country=3\n",
    "        else:\n",
    "            col_country=0\n",
    "        oneHot_col_country=np.eye(3+1)[col_country]\n",
    "    \n",
    "        col_hits=math.log10(int(row['hits'])*1.0)\n",
    "    \n",
    "        if row['bounces']==\"1\":\n",
    "            col_bounces=1\n",
    "        else:\n",
    "            col_bounces=0\n",
    "\n",
    "        if row['newVisits']== \"1\":\n",
    "            col_newVisits=1\n",
    "        else:\n",
    "            col_newVisits=0\n",
    "    \n",
    "        if row['source']==\"mail.googleplex.com\" or row['source']==\"dfa\":\n",
    "            col_source =1\n",
    "        elif row['source']==\"(direct)\":\n",
    "            col_source=2\n",
    "        else:\n",
    "            col_source=0\n",
    "        oneHot_col_source=np.eye(2+1)[col_source]\n",
    "        \n",
    "        if row['medium']==\"cpm\":\n",
    "            col_medium=1\n",
    "        else:\n",
    "            col_medium=0\n",
    "        oneHot_col_medium=np.eye(1+1)[col_medium]\n",
    "    \n",
    "        if row['isTrueDirect']==\"1\":\n",
    "            col_isTrueDirect=1\n",
    "        else:\n",
    "            col_isTrueDirect=0\n",
    "    \n",
    "        revenue = math.log(int(row['transactionRevenue'])+1)\n",
    "    \n",
    "        l=[oneHot_col_channelGrouping,[col_visitNumber],[col_isMobile],oneHot_col_country,[col_hits],[col_bounces],[col_newVisits],oneHot_col_source,oneHot_col_medium,[col_isTrueDirect]]\n",
    "        data.append(list(chain.from_iterable(l)))\n",
    "        ans.append(revenue)\n",
    "    \n",
    "    return(data,ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10000)\n",
      "(20000, 20000)\n",
      "(30000, 30000)\n",
      "(40000, 40000)\n",
      "(50000, 50000)\n",
      "(60000, 60000)\n",
      "(70000, 70000)\n",
      "(80000, 80000)\n",
      "(90000, 90000)\n",
      "(100000, 100000)\n",
      "(110000, 110000)\n",
      "(120000, 120000)\n",
      "(130000, 130000)\n",
      "(140000, 140000)\n",
      "(150000, 150000)\n",
      "(160000, 160000)\n",
      "(170000, 170000)\n",
      "(180000, 180000)\n",
      "(190000, 190000)\n",
      "(200000, 200000)\n",
      "(210000, 210000)\n",
      "(220000, 220000)\n",
      "(230000, 230000)\n",
      "(240000, 240000)\n",
      "(250000, 250000)\n",
      "(260000, 260000)\n",
      "(270000, 270000)\n",
      "(280000, 280000)\n",
      "(290000, 290000)\n",
      "(300000, 300000)\n",
      "(310000, 310000)\n",
      "(320000, 320000)\n",
      "(330000, 330000)\n",
      "(340000, 340000)\n",
      "(350000, 350000)\n",
      "(360000, 360000)\n",
      "(370000, 370000)\n",
      "(380000, 380000)\n",
      "(390000, 390000)\n",
      "(400000, 400000)\n",
      "(410000, 410000)\n",
      "(420000, 420000)\n",
      "(430000, 430000)\n",
      "(440000, 440000)\n",
      "(450000, 450000)\n",
      "(460000, 460000)\n",
      "(470000, 470000)\n",
      "(480000, 480000)\n",
      "(490000, 490000)\n",
      "(500000, 500000)\n",
      "(510000, 510000)\n",
      "(520000, 520000)\n",
      "(530000, 530000)\n",
      "(540000, 540000)\n",
      "(550000, 550000)\n",
      "(560000, 560000)\n",
      "(570000, 570000)\n",
      "(580000, 580000)\n",
      "(590000, 590000)\n",
      "(600000, 600000)\n",
      "(610000, 610000)\n",
      "(620000, 620000)\n",
      "(630000, 630000)\n",
      "(640000, 640000)\n",
      "(650000, 650000)\n",
      "(660000, 660000)\n",
      "(670000, 670000)\n",
      "(680000, 680000)\n",
      "(690000, 690000)\n",
      "(700000, 700000)\n",
      "(710000, 710000)\n",
      "(720000, 720000)\n",
      "(730000, 730000)\n",
      "(740000, 740000)\n",
      "(750000, 750000)\n",
      "(760000, 760000)\n",
      "(770000, 770000)\n",
      "(780000, 780000)\n",
      "(790000, 790000)\n",
      "(800000, 800000)\n",
      "(810000, 810000)\n",
      "(820000, 820000)\n",
      "(830000, 830000)\n",
      "(840000, 840000)\n",
      "(850000, 850000)\n",
      "(860000, 860000)\n",
      "(870000, 870000)\n",
      "(880000, 880000)\n",
      "(890000, 890000)\n",
      "(900000, 900000)\n",
      "(903553, 903553)\n",
      "[[0.0, 0.0, 1.0, 1.0, 0, 1.0, 0.0, 0.0, 0.0, 0.0, 1, 0, 1.0, 0.0, 0.0, 1.0, 0.0, 0], [0.0, 0.0, 1.0, 0.2, 0, 1.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 1.0, 0.0, 0.0, 1.0, 0.0, 0], [0.0, 0.0, 1.0, 0.2, 0, 1.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 1.0, 0.0, 0.0, 1.0, 0.0, 0]]\n"
     ]
    }
   ],
   "source": [
    "while(es_s_size>0):\n",
    "    data,ans=setByScroll(res,data,ans)\n",
    "    res=escon.scroll(scroll_id=es_s_id,scroll=es_s_time)\n",
    "    es_s_id=res['_scroll_id']\n",
    "    es_s_size=len(res[\"hits\"][\"hits\"])\n",
    "    print(len(data),len(ans))\n",
    "\n",
    "datalength=len(data)\n",
    "print(data[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x:', TensorShape([Dimension(None), Dimension(18)]), 'a:', TensorShape([Dimension(18), Dimension(1)]))\n"
     ]
    }
   ],
   "source": [
    "#tensorflowセットアップ\n",
    "\n",
    "#print(data[0],ans[0])\n",
    "#inputData=tf.transpose(data)\n",
    "debugFlg=False\n",
    "batch_size=datalength/2\n",
    "num_elements=18\n",
    "P=36\n",
    "num_rows=len(data)\n",
    "inputData=np.reshape(data,(num_rows,num_elements))\n",
    "inputAns=np.reshape(ans,(num_rows,1))\n",
    "x =tf.placeholder(\"float\",[None,num_elements])\n",
    "y_=tf.placeholder(\"float\",[None,1])\n",
    "\n",
    "a=tf.Variable( tf.random_uniform([num_elements,1],-1.0,1.0),name=\"weights\")    \n",
    "w1=tf.Variable( tf.random_uniform([num_elements,P],-1.0,1.0 )  )\n",
    "w2=tf.Variable( tf.random_uniform([P,1],-1.0,1.0 )  )\n",
    "#a=tf.Variable( tf.random_uniform([[18]],-1.0,1.0),name=\"weights\")    \n",
    "#b=tf.Variable(tf.zeros([1,1]),name=\"intercept\")\n",
    "b=tf.Variable(tf.random_normal([P]),name=\"intercept\")\n",
    "print(\"x:\",x.shape,\"a:\",a.shape)\n",
    "#y=tf.matmul(tf.transpose(a),x)+b\n",
    "#y=tf.matmul(x,a)\n",
    "x2=tf.sigmoid(tf.matmul(x,w1))+b\n",
    "y=tf.matmul(x2,w2)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "loss = tf.reduce_sum(tf.square(y_-y))/batch_size\n",
    "train_step=tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初期状態\n",
      "\n",
      "Step: 2500\n",
      "誤差3.51403\n",
      "\n",
      "Step: 5000\n",
      "誤差3.41898\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6892770028f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mbatchInputData\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0minputData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdatalength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdatalength\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatalength\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mbatchInputAns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputAns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdatalength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdatalength\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatalength\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatchInputData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatchInputAns\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrepeatAll\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mgraphNum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nStep: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kaggleuser/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kaggleuser/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kaggleuser/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kaggleuser/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kaggleuser/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kaggleuser/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#データ表示用セットアップ\n",
    "graphLoss=[]\n",
    "graphStep=[]\n",
    "graphNum=20\n",
    "repeatAll=50000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print('初期状態')\n",
    "    inpShape=inputData[0:batch_size]\n",
    "    ansShape=inputAns[0:batch_size]\n",
    "    #print('誤差' + str(sess.run(loss, feed_dict={x: inputData[0:batch_size], y_: inputAns[0:batch_size]})))\n",
    "    ##print('誤差' + str(sess.run(loss, feed_dict={x: inpShape, y_: ansShape})))\n",
    "    #print(\"weigths: %f, intercept: %f\" % (sess.run(a), sess.run(b) ))\n",
    "    #print(\"input:\",inputAns[batch_size*step+1:batch_size*step+1+batch_size])\n",
    "    ##print(\"weigths:\",sess.run(a),\"intercept:\",sess.run(b) )\n",
    "    \n",
    "    for step in range(repeatAll):\n",
    "        if (batch_size*step) %datalength < (batch_size*step+batch_size) %datalength :\n",
    "            batchInputData= inputData[(batch_size*step)%datalength:(batch_size*step+batch_size)%datalength]\n",
    "            batchInputAns = inputAns[(batch_size*step)%datalength:(batch_size*step+batch_size)%datalength]\n",
    "        else:\n",
    "            batchInputData= inputData[(batch_size*step)%datalength:min( (batch_size*step+batch_size)%datalength,datalength-1 )]\n",
    "            batchInputAns = inputAns[(batch_size*step)%datalength:min( (batch_size*step+batch_size)%datalength,datalength-1) ]\n",
    "        sess.run(train_step, feed_dict={x: batchInputData, y_: batchInputAns })\n",
    "        if (step+1) % (repeatAll/graphNum) == 0:\n",
    "            print('\\nStep: %s' % (step+1))\n",
    "            print('誤差' + str(sess.run(loss, feed_dict={x: batchInputData, y_: batchInputAns })))\n",
    "            if debugFlg==True:\n",
    "                print(\"weights:\",sess.run(a), \" intercept: %f\" % ( sess.run(b)))\n",
    "            graphLoss.append( sess.run(loss, feed_dict={x: batchInputData, y_: batchInputAns }) )\n",
    "            graphStep.append(step)\n",
    "    #最終状態を表示\n",
    "    print(\"weights1:\",sess.run(w1),\"weights2:\",sess.run(w2), \" intercept:\", sess.run(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(graphStep,graphLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
